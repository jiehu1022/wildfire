{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method 1: Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nsemble method to try is regular majority vote\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from scipy import stats\n",
    "import cellpylib as cpl\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the traing set here itself for easy access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('weatherdatafrom12-19_with_fire_v1.csv')\n",
    "cols=['TEMP','DEWP','SLP','STP','VISIB','WDSP','MXSPD','GUST','MAX','MIN','PRCP']\n",
    "X = data[cols]\n",
    "y=data['Class']\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Imputation of missing values\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled.mean(axis=0)\n",
    "X_scaled.std(axis=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "scaler.mean_\n",
    "scaler.scale_ \n",
    "X = scaler.transform(X)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "logistic_model = pickle.load(open(\"Weather_SVM.pickle\", 'rb'))\n",
    "random_forest_model = pickle.load(open(\"Weather_RandomForest.pickle\", 'rb'))\n",
    "from tensorflow import keras\n",
    "cnn_model = keras.models.load_model('NDVI_CNN.h5')\n",
    "'''model = keras.models.load_model('NDVI_CNN.model.h5', custom_objects={\n",
    "    'Adam': lambda **kwargs: hvd.DistributedOptimizer(keras.optimizers.Adam(learning_rate=0.001))\n",
    "})'''\n",
    "\n",
    "#nb_model= pickle.load(open(\"../NB_Model_pickle\", 'rb'))\n",
    "\n",
    "#dtree_model= pickle.load(open(\"../DTree_model_pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('../test_data/test.np.npy')\n",
    "#Y = np.load('../test_data/test_labels.np.npy')\n",
    "X = X_test\n",
    "Y = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = logistic_model.predict(X)\n",
    "print(log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = random_forest_model.predict(X)\n",
    "print(rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = np.vstack((log_pred, rf_pred ) )\n",
    "#comb = np.vstack((log_pred, rf_pred, knn_pred, dtree_pred) )\n",
    "vote = stats.mode(comb, axis=0)\n",
    "Y_pred = vote[0][0]\n",
    "\n",
    "c = np.logical_xor(Y_pred, Y.T[0])\n",
    "incorrect =np.sum(c)\n",
    "accuracy = 1 - (incorrect/Y.shape[0])\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matx = confusion_matrix(y_test, Y_pred)\n",
    "sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method 2: Majority voting using cellular automata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying ensemble method 1 - Apply rule 232\n",
    "# Rule = Mod[p q + p r + q r, 2]\n",
    "\n",
    "#cellular_automaton = cpl.init_random(5)\n",
    "#print(cellular_automaton)\n",
    "ca_list = []\n",
    "titles = []\n",
    "i= 1\n",
    "for column in comb.T:\n",
    "   \n",
    "    cellular_automaton = np.array([column])\n",
    "    \n",
    "     #This line will be the actual classifier output\n",
    "\n",
    "    c = mpl.colors.ListedColormap(['green', 'red', 'black', 'gray'])\n",
    "    n = mpl.colors.Normalize(vmin=0,vmax=3)   \n",
    "\n",
    "\n",
    "    # evolve the CA for 100 time steps, using Rule 232 as defined in NKS\n",
    "    cellular_automaton = cpl.evolve(cellular_automaton, timesteps=100, \n",
    "                                apply_rule=lambda n, c, t: cpl.nks_rule(n, 232))\n",
    "    titles.append(\"Vote for \" + str(i))\n",
    "    i+=1\n",
    "    ca_list.append(cellular_automaton)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#votes = [ca_list.apply(lambda x : np.argmax(np.bincount(x[49])))]\n",
    "votes = map(lambda x : np.argmax(np.bincount(x[99])), ca_list)\n",
    "Y_pred = np.array(list(votes))\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.logical_xor(Y_pred, Y.T[0])\n",
    "incorrect =np.sum(c)\n",
    "accuracy = 1 - (incorrect/Y.shape[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpl.plot_multiple(ca_list, titles)\n",
    "fig = plt.figure(figsize=(30,10)) \n",
    "\n",
    "gs = gridspec.GridSpec(cellular_automaton.shape[0], cellular_automaton.shape[1])\n",
    "\n",
    "maxj=cellular_automaton.shape[0]\n",
    "maxk = cellular_automaton.shape[1]\n",
    "\n",
    "j=0\n",
    "k=0\n",
    "for i in ca_list:\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(gs[j, k])\n",
    "    ax.set_ylabel('time') \n",
    "    fig.add_subplot(ax) \n",
    "    if k >= maxk-1 :\n",
    "        k = 0\n",
    "        if j >= maxj-1:\n",
    "            j +=  0\n",
    "        else:\n",
    "            j+=1\n",
    "    else:\n",
    "        k +=1\n",
    "    \n",
    "        \n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method 3 : Classificational Cellular automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inference Algorithm:\n",
    "    Input: a sample for classification \n",
    "    Number of iterations: t=1,2,...V \n",
    "For t=1,2...V \n",
    "    -each cell in automaton classifies the sample\n",
    "    -change cells energy according to the transaction rules \n",
    "    -each cell with energy below zero does not survive\n",
    "Classify the sample according to the weighted voting of the survived cells \n",
    "\n",
    "Output: class of the input sample  \n",
    "    \n",
    "Transaction rules:\n",
    "    score = support * distance\n",
    "    \n",
    "\n",
    "(4) (PDF) Machine-Learning with Cellular Automata. Available from: https://www.researchgate.net/publication/221460875_Machine-Learning_with_Cellular_Automata [accessed May 06 2019].`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(X.shape[0], size=1)\n",
    "print(ind)\n",
    "X_test = X[ind, :]\n",
    "print(Y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [logistic_model, random_forest_model]\n",
    "\n",
    "\n",
    "preds_list = []\n",
    "for model in models_list:\n",
    "    preds_list.append(model.predict(X_test))\n",
    "    \n",
    "print(np.asarray(preds_list).flatten())\n",
    "np.asarray(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
