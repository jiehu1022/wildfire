{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method 1: Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nsemble method to try is regular majority vote\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from scipy import stats\n",
    "import cellpylib as cpl\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the weather training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('weatherdatafrom12-19_with_fire_v1.csv')\n",
    "cols=['TEMP','DEWP','SLP','STP','VISIB','WDSP','MXSPD','GUST','MAX','MIN','PRCP']\n",
    "X = data[cols]\n",
    "y=data['Class']\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Imputation of missing values\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled.mean(axis=0)\n",
    "X_scaled.std(axis=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "scaler.mean_\n",
    "scaler.scale_ \n",
    "X = scaler.transform(X)\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.array(ast.literal_eval(array_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(data):\n",
    "    nx, ny = data.shape\n",
    "    return data.reshape((1,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get remote sensing test data\n",
    "df = pd.read_csv('testdata.csv')\n",
    "df['image'] = df['image'].apply(lambda x : reshape_data(from_np_array(x)))\n",
    "X1 = df[\"image\"]\n",
    "Y1 = df[\"fire_nofire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "svm_model = pickle.load(open(\"Weather_SVM.pickle\", 'rb'))\n",
    "random_forest_model = pickle.load(open(\"Weather_RandomForest.pickle\", 'rb'))\n",
    "from tensorflow import keras\n",
    "cnn_model = keras.models.load_model('NDVI_CNN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "Y = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm_model.predict(X)\n",
    "rf_pred = random_forest_model.predict(X)\n",
    "cnn_pred = cnn_model.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = np.vstack((log_pred, rf_pred,cnn_pred ) )\n",
    "vote = stats.mode(comb, axis=0)\n",
    "Y_pred = vote[0][0]\n",
    "\n",
    "c = np.logical_xor(Y_pred, Y.T[0])\n",
    "incorrect =np.sum(c)\n",
    "accuracy = 1 - (incorrect/Y.shape[0])\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matx = confusion_matrix(y_test, Y_pred)\n",
    "sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
